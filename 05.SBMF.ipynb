{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import inflect\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import re\n",
    "from word2number import w2n\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import log\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import random\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../movies_train.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "with open('../movies_test.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)\n",
    "with open('../movies_validation.pkl', 'rb') as f:\n",
    "    valid_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example link\n",
    "- https://github.com/PreferredAI/recommendation-retrieval/blob/37da288631267e8099ca60b94d172c5baa5be400/Part-1-Matrix-Factorization-Recommendation-Retrieval.ipynb\n",
    "\n",
    "\n",
    "1. 일단 ProbabilisticeMatrixFactorization.py 파일의 fit 부분 잘 봐\n",
    "2. 보면, train, test data input으로 넣게 되어 있음.\n",
    "3. 난 이미 train, test 나뉘어져 있기 때문에 이걸 여기서 원하는 형태로 잘 만들어놔줘\n",
    "4. 이 때, sentiment train, test  //  rating train, test 총 4개 준비해둬.\n",
    "5. fit 함수의 self.mean_inv 보면 train_vec의 rating 부분 활용하고 있는거 볼 수 있음.\n",
    "6. 이 부분을 잘 수정해서 SBMF 만들어야해. \n",
    "7. fit 안에 rmse도 있는데, mae도 추가해야해.\n",
    "8. sentiment를 어떻게 녹여놓는가가 관건\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>compound</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>NeMFRating</th>\n",
       "      <th>SBMFRating</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633870</th>\n",
       "      <td>143756</td>\n",
       "      <td>31800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115182</th>\n",
       "      <td>272600</td>\n",
       "      <td>13746</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383131</th>\n",
       "      <td>208589</td>\n",
       "      <td>23849</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10.53</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079042</th>\n",
       "      <td>182422</td>\n",
       "      <td>14736</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.20</td>\n",
       "      <td>9.24</td>\n",
       "      <td>8.40</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.56</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.20</td>\n",
       "      <td>14.29</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651398</th>\n",
       "      <td>56973</td>\n",
       "      <td>53386</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>18.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.64</td>\n",
       "      <td>40.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318060</th>\n",
       "      <td>202972</td>\n",
       "      <td>31547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103736</th>\n",
       "      <td>184594</td>\n",
       "      <td>53967</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505244</th>\n",
       "      <td>43893</td>\n",
       "      <td>26640</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.17</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5.43</td>\n",
       "      <td>10.87</td>\n",
       "      <td>9.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906648</th>\n",
       "      <td>79756</td>\n",
       "      <td>15221</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415637</th>\n",
       "      <td>211517</td>\n",
       "      <td>52836</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572548 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  movieID  rating  compound  senti_score  NeMFRating  \\\n",
       "1633870  143756    31800     5.0    0.5719            3           3   \n",
       "3115182  272600    13746     5.0    0.0000            2           3   \n",
       "2383131  208589    23849     3.0   -0.2023            1           2   \n",
       "2079042  182422    14736     4.0    0.9666            3           3   \n",
       "651398    56973    53386     5.0    0.9260            3           3   \n",
       "...         ...      ...     ...       ...          ...         ...   \n",
       "2318060  202972    31547     4.0    0.4404            3           3   \n",
       "2103736  184594    53967     5.0    0.9277            3           3   \n",
       "505244    43893    26640     4.0    0.9531            3           3   \n",
       "906648    79756    15221     5.0    0.6369            3           3   \n",
       "2415637  211517    52836     5.0    0.0000            2           3   \n",
       "\n",
       "         SBMFRating  anger  anticipation  disgust   fear    joy  sadness  \\\n",
       "1633870           4   0.00          0.00     0.00   0.00  16.67     0.00   \n",
       "3115182           3   0.00         11.11     0.00  11.11   0.00     0.00   \n",
       "2383131           3  10.53          5.26     5.26   5.26   0.00     5.26   \n",
       "2079042           5   5.04          4.20     9.24   8.40   6.72     7.56   \n",
       "651398            5   0.00         27.27     0.00   4.55  18.18     0.00   \n",
       "...             ...    ...           ...      ...    ...    ...      ...   \n",
       "2318060           4   0.00          3.57     0.00   0.00   3.57     0.00   \n",
       "2103736           5   0.00          6.67     0.00   6.67  20.00     0.00   \n",
       "505244            5   2.17          6.52     1.09   0.00   6.52     1.09   \n",
       "906648            4   0.00          0.00     0.00   0.00  50.00     0.00   \n",
       "2415637           3   0.00          0.00     0.00   0.00   0.00     0.00   \n",
       "\n",
       "         surprise  trust  negative  positive  \n",
       "1633870      0.00  33.33      0.00     16.67  \n",
       "3115182      0.00  11.11      0.00      0.00  \n",
       "2383131      5.26   5.26     10.53     10.53  \n",
       "2079042      5.04   4.20     14.29     13.45  \n",
       "651398      13.64  40.91      0.00     27.27  \n",
       "...           ...    ...       ...       ...  \n",
       "2318060      3.57   7.14      0.00      3.57  \n",
       "2103736      6.67   0.00      0.00     26.67  \n",
       "505244       3.26   5.43     10.87      9.78  \n",
       "906648       0.00  50.00      0.00     50.00  \n",
       "2415637      0.00   0.00      0.00    100.00  \n",
       "\n",
       "[2572548 rows x 17 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_set.append(valid_set)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SBMFRating 타입 float으로 바꾸기\n",
    "# train_data = train_data.astype({'SBMFRating':'float'})\n",
    "# test_set = test_set.astype({'SBMFRating':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = train_data[['userID', 'movieID', 'SBMFRating']]\n",
    "test_s = test_set[['userID', 'movieID', 'SBMFRating']]\n",
    "\n",
    "\n",
    "train_pmf = train_data[['userID', 'movieID', 'rating']]\n",
    "test_pmf = test_set[['userID', 'movieID', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rating_data(df):\n",
    "\n",
    "    prefer = []\n",
    "\n",
    "    ls = df.values.tolist()\n",
    "    for line in ls:  # 打开指定文件\n",
    "        (userID, movieID, rating) = line  # 数据集中每行有4项\n",
    "        uid = int(userID)\n",
    "        mid = int(movieID)\n",
    "        rat = float(rating)\n",
    "        prefer.append([uid, mid, rat])\n",
    "    data = np.array(prefer)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = load_rating_data(train_s)\n",
    "tests = load_rating_data(test_s)\n",
    "trainpmf = load_rating_data(train_pmf)\n",
    "testpmf = load_rating_data(test_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.43756e+05, 3.18000e+04, 5.00000e+00],\n",
       "       [2.72600e+05, 1.37460e+04, 5.00000e+00],\n",
       "       [2.08589e+05, 2.38490e+04, 3.00000e+00],\n",
       "       ...,\n",
       "       [4.38930e+04, 2.66400e+04, 4.00000e+00],\n",
       "       [7.97560e+04, 1.52210e+04, 5.00000e+00],\n",
       "       [2.11517e+05, 5.28360e+04, 5.00000e+00]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 왜...이런거죠\n",
    "trainpmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sbmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF(object):\n",
    "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        self.num_feat = num_feat  # Number of latent features,\n",
    "        self.epsilon = epsilon  # learning rate,\n",
    "        self._lambda = _lambda  # L2 regularization,\n",
    "        self.momentum = momentum  # momentum of the gradient,\n",
    "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
    "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
    "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
    "\n",
    "        self.w_Item = None  # Item feature vectors\n",
    "        self.w_User = None  # User feature vectors\n",
    "\n",
    "        self.rmse_train = []\n",
    "        self.rmse_test = []\n",
    "\n",
    "        self.mae_train = []\n",
    "        self.mae_test = []\n",
    "\n",
    "    # ***Fit the model with train_tuple and evaluate RMSE on both train and test data.  ***********#\n",
    "    # ***************** train_vec=TrainData, test_vec=TestData*************#\n",
    "    def fit(self, train_vec, test_vec):\n",
    "\n",
    "        # mean subtraction\n",
    "        self.mean_inv = np.mean(train_vec[:, 2])  # 评分平均值\n",
    "\n",
    "        pairs_train = train_vec.shape[0]  # traindata 中条目数\n",
    "        pairs_test = test_vec.shape[0]  # testdata中条目数\n",
    "\n",
    "        # 1-p-i, 2-m-c\n",
    "        num_user = int(max(np.amax(train_vec[:, 0]), np.amax(test_vec[:, 0]))) + 1  # 第0列，user总数\n",
    "        num_item = int(max(np.amax(train_vec[:, 1]), np.amax(test_vec[:, 1]))) + 1  # 第1列，movie总数\n",
    "\n",
    "        incremental = False  # 增量\n",
    "        if ((not incremental) or (self.w_Item is None)):\n",
    "            # initialize\n",
    "            self.epoch = 0\n",
    "            self.w_Item = 0.1 * np.random.randn(num_item, self.num_feat)  # numpy.random.randn 电影 M x D 正态分布矩阵\n",
    "            self.w_User = 0.1 * np.random.randn(num_user, self.num_feat)  # numpy.random.randn 用户 N x D 正态分布矩阵\n",
    "\n",
    "            self.w_Item_inc = np.zeros((num_item, self.num_feat))  # 创建电影 M x D 0矩阵\n",
    "            self.w_User_inc = np.zeros((num_user, self.num_feat))  # 创建用户 N x D 0矩阵\n",
    "\n",
    "        while self.epoch < self.maxepoch:  # 检查迭代次数\n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])  # 根据记录数创建等差array\n",
    "            np.random.shuffle(shuffled_order)  # 用于将一个列表中的元素打乱\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches):  # 每次迭代要使用的数据量\n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
    "                batch_idx = np.mod(test, shuffled_order.shape[0])  # 本次迭代要使用的索引下标\n",
    "\n",
    "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Objective Function\n",
    "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID, :],\n",
    "                                              self.w_Item[batch_ItemID, :]),\n",
    "                                  axis=1)  # mean_inv subtracted # np.multiply对应位置元素相乘\n",
    "\n",
    "                rawErr = pred_out - train_vec[shuffled_order[batch_idx], 2] + self.mean_inv\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
    "                       + self._lambda * self.w_User[batch_UserID, :]\n",
    "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
    "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
    "\n",
    "                dw_Item = np.zeros((num_item, self.num_feat))\n",
    "                dw_User = np.zeros((num_user, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
    "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
    "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
    "\n",
    "                self.w_Item = self.w_Item - self.w_Item_inc\n",
    "                self.w_User = self.w_User - self.w_User_inc\n",
    "\n",
    "                # Compute Objective Function after\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_User[np.array(train_vec[:, 0], dtype='int32'), :],\n",
    "                                                  self.w_Item[np.array(train_vec[:, 1], dtype='int32'), :]),\n",
    "                                      axis=1)  # mean_inv subtracted\n",
    "                    rawErr = pred_out - train_vec[:, 2] + self.mean_inv\n",
    "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
    "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
    "\n",
    "                        \n",
    "\n",
    "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_User[np.array(test_vec[:, 0], dtype='int32'), :],\n",
    "                                                  self.w_Item[np.array(test_vec[:, 1], dtype='int32'), :]),\n",
    "                                      axis=1)  # mean_inv subtracted\n",
    "                    rawErr = pred_out - test_vec[:, 2] + self.mean_inv\n",
    "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_test))\n",
    "\n",
    "                    # Print info\n",
    "                    if batch == self.num_batches - 1:\n",
    "                        print('Training RMSE: %f, Test RMSE %f' % (self.rmse_train[-1], self.rmse_test[-1]))\n",
    "        \n",
    "        return self.rmse_train, self.rmse_test\n",
    "\n",
    "\n",
    "    def predict(self, invID):\n",
    "        return np.dot(self.w_Item, self.w_User[int(invID), :]) + self.mean_inv  # numpy.dot 点乘\n",
    "\n",
    "    # ****************Set parameters by providing a parameter dictionary.  ***********#\n",
    "    def set_params(self, parameters):\n",
    "        if isinstance(parameters, dict):\n",
    "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
    "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
    "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
    "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
    "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
    "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
    "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
    "\n",
    "    def topK(self, test_vec, k=10):\n",
    "        inv_lst = np.unique(test_vec[:, 0])\n",
    "        pred = {}\n",
    "        for inv in inv_lst:\n",
    "            if pred.get(inv, None) is None:\n",
    "                pred[inv] = np.argsort(self.predict(inv))[-k:]  # numpy.argsort索引排序\n",
    "\n",
    "        intersection_cnt = {}\n",
    "        for i in range(test_vec.shape[0]):\n",
    "            if test_vec[i, 1] in pred[test_vec[i, 0]]:\n",
    "                intersection_cnt[test_vec[i, 0]] = intersection_cnt.get(test_vec[i, 0], 0) + 1\n",
    "        invPairs_cnt = np.bincount(np.array(test_vec[:, 0], dtype='int32'))\n",
    "\n",
    "        precision_acc = 0.0\n",
    "        recall_acc = 0.0\n",
    "        for inv in inv_lst:\n",
    "            precision_acc += intersection_cnt.get(inv, 0) / float(k)\n",
    "            recall_acc += intersection_cnt.get(inv, 0) / float(invPairs_cnt[int(inv)])\n",
    "\n",
    "        return precision_acc / len(inv_lst), recall_acc / len(inv_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = PMF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 1.050220, Test RMSE 1.051084\n",
      "Training RMSE: 1.050211, Test RMSE 1.051083\n",
      "Training RMSE: 1.050202, Test RMSE 1.051082\n",
      "Training RMSE: 1.050192, Test RMSE 1.051081\n",
      "Training RMSE: 1.050183, Test RMSE 1.051079\n",
      "Training RMSE: 1.050173, Test RMSE 1.051079\n",
      "Training RMSE: 1.050164, Test RMSE 1.051078\n",
      "Training RMSE: 1.050155, Test RMSE 1.051077\n",
      "Training RMSE: 1.050146, Test RMSE 1.051075\n",
      "Training RMSE: 1.050138, Test RMSE 1.051072\n",
      "Training RMSE: 1.050129, Test RMSE 1.051070\n",
      "Training RMSE: 1.050120, Test RMSE 1.051069\n",
      "Training RMSE: 1.050111, Test RMSE 1.051068\n",
      "Training RMSE: 1.050102, Test RMSE 1.051066\n",
      "Training RMSE: 1.050094, Test RMSE 1.051065\n",
      "Training RMSE: 1.050085, Test RMSE 1.051064\n",
      "Training RMSE: 1.050076, Test RMSE 1.051064\n",
      "Training RMSE: 1.050068, Test RMSE 1.051064\n",
      "Training RMSE: 1.050059, Test RMSE 1.051063\n",
      "Training RMSE: 1.050051, Test RMSE 1.051062\n"
     ]
    }
   ],
   "source": [
    "rmse_train1, rmse_test1 = pmf.fit(trains, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rmse_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbmf(train, test, train_s, test_s):\n",
    "     pmf = PMF()\n",
    "     pmf_origin = pmf.fit(train, test)\n",
    "     pmf_senti = pmf.fit(train_s, test_s)\n",
    "     sbmf = 0.5*pmf_origin + 0.5*pmf_senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBMF(with surprise package)\n",
    "- 쉽게가면.... svd(bias=FALSE) 해주면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, KNNBasic, KNNWithMeans, KNNBaseline, NMF\n",
    "from surprise import dump\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../movies_train.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "with open('../movies_test.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)\n",
    "with open('../movies_validation.pkl', 'rb') as f:\n",
    "    valid_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>compound</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>NeMFRating</th>\n",
       "      <th>SBMFRating</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633870</th>\n",
       "      <td>143756</td>\n",
       "      <td>31800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115182</th>\n",
       "      <td>272600</td>\n",
       "      <td>13746</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383131</th>\n",
       "      <td>208589</td>\n",
       "      <td>23849</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10.53</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079042</th>\n",
       "      <td>182422</td>\n",
       "      <td>14736</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.20</td>\n",
       "      <td>9.24</td>\n",
       "      <td>8.40</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.56</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.20</td>\n",
       "      <td>14.29</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651398</th>\n",
       "      <td>56973</td>\n",
       "      <td>53386</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>18.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.64</td>\n",
       "      <td>40.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318060</th>\n",
       "      <td>202972</td>\n",
       "      <td>31547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103736</th>\n",
       "      <td>184594</td>\n",
       "      <td>53967</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505244</th>\n",
       "      <td>43893</td>\n",
       "      <td>26640</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.17</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5.43</td>\n",
       "      <td>10.87</td>\n",
       "      <td>9.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906648</th>\n",
       "      <td>79756</td>\n",
       "      <td>15221</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415637</th>\n",
       "      <td>211517</td>\n",
       "      <td>52836</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572548 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  movieID  rating  compound  senti_score  NeMFRating  \\\n",
       "1633870  143756    31800     5.0    0.5719            3           3   \n",
       "3115182  272600    13746     5.0    0.0000            2           3   \n",
       "2383131  208589    23849     3.0   -0.2023            1           2   \n",
       "2079042  182422    14736     4.0    0.9666            3           3   \n",
       "651398    56973    53386     5.0    0.9260            3           3   \n",
       "...         ...      ...     ...       ...          ...         ...   \n",
       "2318060  202972    31547     4.0    0.4404            3           3   \n",
       "2103736  184594    53967     5.0    0.9277            3           3   \n",
       "505244    43893    26640     4.0    0.9531            3           3   \n",
       "906648    79756    15221     5.0    0.6369            3           3   \n",
       "2415637  211517    52836     5.0    0.0000            2           3   \n",
       "\n",
       "         SBMFRating  anger  anticipation  disgust   fear    joy  sadness  \\\n",
       "1633870           4   0.00          0.00     0.00   0.00  16.67     0.00   \n",
       "3115182           3   0.00         11.11     0.00  11.11   0.00     0.00   \n",
       "2383131           3  10.53          5.26     5.26   5.26   0.00     5.26   \n",
       "2079042           5   5.04          4.20     9.24   8.40   6.72     7.56   \n",
       "651398            5   0.00         27.27     0.00   4.55  18.18     0.00   \n",
       "...             ...    ...           ...      ...    ...    ...      ...   \n",
       "2318060           4   0.00          3.57     0.00   0.00   3.57     0.00   \n",
       "2103736           5   0.00          6.67     0.00   6.67  20.00     0.00   \n",
       "505244            5   2.17          6.52     1.09   0.00   6.52     1.09   \n",
       "906648            4   0.00          0.00     0.00   0.00  50.00     0.00   \n",
       "2415637           3   0.00          0.00     0.00   0.00   0.00     0.00   \n",
       "\n",
       "         surprise  trust  negative  positive  \n",
       "1633870      0.00  33.33      0.00     16.67  \n",
       "3115182      0.00  11.11      0.00      0.00  \n",
       "2383131      5.26   5.26     10.53     10.53  \n",
       "2079042      5.04   4.20     14.29     13.45  \n",
       "651398      13.64  40.91      0.00     27.27  \n",
       "...           ...    ...       ...       ...  \n",
       "2318060      3.57   7.14      0.00      3.57  \n",
       "2103736      6.67   0.00      0.00     26.67  \n",
       "505244       3.26   5.43     10.87      9.78  \n",
       "906648       0.00  50.00      0.00     50.00  \n",
       "2415637      0.00   0.00      0.00    100.00  \n",
       "\n",
       "[2572548 rows x 17 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_set.append(valid_set)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = train_data[['userID', 'movieID', 'SBMFRating']]\n",
    "test_s = test_set[['userID', 'movieID', 'SBMFRating']]\n",
    "\n",
    "\n",
    "train_pmf = train_data[['userID', 'movieID', 'rating']]\n",
    "test_pmf = test_set[['userID', 'movieID', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 쓰려면 이거 설정해줘야함.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# train, test set 완성\n",
    "trainset = Dataset.load_from_df(train_data[['userID', 'movieID', 'rating']], reader)\n",
    "trainset = trainset.build_full_trainset()\n",
    "\n",
    "testset = Dataset.load_from_df(test_set[['userID', 'movieID', 'rating']], reader)\n",
    "testset = testset.construct_testset(testset.raw_ratings)\n",
    "\n",
    "\n",
    "train_s = Dataset.load_from_df(train_data[['userID', 'movieID', 'SBMFRating']], reader)\n",
    "train_s = train_s.build_full_trainset()\n",
    "\n",
    "\n",
    "test_s = Dataset.load_from_df(test_set[['userID', 'movieID', 'SBMFRating']], reader)\n",
    "test_s = test_s.construct_testset(test_s.raw_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of k size\n",
    "k = [i for i in range(5,26,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 사용\n",
    "def pmf(train, test, i):\n",
    "     mae_pmf = []\n",
    "     rmse_pmf = []\n",
    "\n",
    "     algo = SVD(biased=False, n_factors=i, verbose = 0) # The number of iteration of the SGD procedure.\n",
    "     np.random.seed(seed_num)\n",
    "\n",
    "     algo.fit(train)\n",
    "     predictions_test = algo.test(test)\n",
    "     error_mae = accuracy.mae(predictions_test, verbose = 0)  \n",
    "     error_rmse = accuracy.rmse(predictions_test, verbose = 0)\n",
    "\n",
    "     mae_pmf.append(error_mae)\n",
    "     rmse_pmf.append(error_rmse)\n",
    "\n",
    "     print(\"K:\", i, \"MAE:\",  error_mae,\"RMSE\",error_rmse)\n",
    "\n",
    "     return mae_pmf, rmse_pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 5 MAE: 0.827064557466473 RMSE 1.1361297486206452\n",
      "[0.827064557466473]\n",
      "[1.1361297486206452]\n",
      "K: 10 MAE: 0.840242351538464 RMSE 1.1461689748498969\n",
      "[0.840242351538464]\n",
      "[1.1461689748498969]\n"
     ]
    }
   ],
   "source": [
    "for i in t:\n",
    "     mae_pmf, rmse_pmf = pmf(train_s,test_s,i)\n",
    "     print(mae_pmf)\n",
    "     print(rmse_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbmf(train, test, train_s, test_s):\n",
    "     mae_sbmf = []\n",
    "     rmse_sbmf = []\n",
    "\n",
    "     algo = SVD(biased=False, n_factors=i, verbose = 0) # The number of iteration of the SGD procedure.\n",
    "     np.random.seed(seed_num)\n",
    "\n",
    "     # 평점으로 pmf\n",
    "     algo.fit(train)\n",
    "     predictions_test = algo.test(test)\n",
    "\n",
    "     predictions = []\n",
    "     for _, _, _, predicted_rating, _ in predictions_test:\n",
    "          # predicted_rating = norm_list(origin_predictions)\n",
    "          predictions.append(predicted_rating)\n",
    "\n",
    "     # sentiment score로 pmf\n",
    "     algo.fit(train_s)\n",
    "     predictions_test_s = algo.test(test_s)\n",
    "\n",
    "     predictions_senti = []\n",
    "     for _, _, _, predicted_rating, _ in predictions_test_s:\n",
    "          # predicted_rating = norm_list(origin_predictions)\n",
    "          predictions_senti.append(predicted_rating)\n",
    "\n",
    "     # sbmf 예상 rating\n",
    "     sbmf_rating= [0.5*(i+j) for i,j in zip(predictions,predictions_senti)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     # 원래 test data의 평점도 리스트로 만들어줌\n",
    "     origin_rating = []\n",
    "     for _, _, rating, _, _ in predictions_test:\n",
    "          origin_rating.append(rating)\n",
    "\n",
    "     # 원래 sentiment의 test data의 평점도 리스트로 만들어줌\n",
    "     senti_rating = []\n",
    "     for _, _, rating, _, _ in predictions_test_s:\n",
    "          senti_rating.append(rating)\n",
    "\n",
    "     # sbmf origin rating\n",
    "     sbmf_origin_rating= [0.5*(i+j) for i,j in zip(origin_rating,senti_rating)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     # rmse, mae 구하기\n",
    "     MAE_temp = mean_absolute_error(sbmf_origin_rating, sbmf_rating)\n",
    "     RMSE_temp = mean_squared_error(sbmf_origin_rating, sbmf_rating, squared = False)\n",
    "\n",
    "     mae_sbmf.append(MAE_temp)\n",
    "     rmse_sbmf.append(RMSE_temp)\n",
    "\n",
    "     print(\"K:\", i, \"MAE:\",  MAE_temp,\"RMSE:\",RMSE_temp)\n",
    "\n",
    "     return mae_sbmf, rmse_sbmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 10 MAE: 0.7146861075283099 RMSE: 0.9846483759583007\n"
     ]
    }
   ],
   "source": [
    "mae_sbmf, rmse_sbmf = sbmf(trainset, testset, train_s, test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 5 MAE: 0.7023097184896899 RMSE: 0.9731539160479578\n",
      "K: 10 MAE: 0.7146861075283099 RMSE: 0.9846483759583007\n",
      "K: 15 MAE: 0.7201372533592957 RMSE: 0.98984873367562\n",
      "K: 20 MAE: 0.7293915618918204 RMSE: 0.9985823601221085\n",
      "K: 25 MAE: 0.7378051637184949 RMSE: 1.0059421695599164\n"
     ]
    }
   ],
   "source": [
    "for i in k:\n",
    "     mae_sbmf, rmse_sbmf = sbmf(trainset, testset, train_s, test_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "janetorch",
   "language": "python",
   "name": "janetorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
