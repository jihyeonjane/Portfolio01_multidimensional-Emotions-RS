{"cells":[{"cell_type":"code","execution_count":1,"id":"6784c730","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7006,"status":"ok","timestamp":1692183220152,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"},"user_tz":-540},"id":"6784c730","outputId":"eb480d6f-e412-4002-cf00-239802d794da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras-self-attention\n","  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.23.5)\n","Building wheels for collected packages: keras-self-attention\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=0edaffdff3bce7fcef08bfd05fcd9e29c7e1720a3a0d410f74818ef0ad9fa308\n","  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n","Successfully built keras-self-attention\n","Installing collected packages: keras-self-attention\n","Successfully installed keras-self-attention-0.51.0\n"]}],"source":["# !pip install -r requirements.txt\n","!pip install keras-self-attention"]},{"cell_type":"markdown","id":"6c7ab7f7","metadata":{"id":"6c7ab7f7"},"source":["# 0. 라이브러리"]},{"cell_type":"markdown","id":"135d9a93","metadata":{"id":"135d9a93"},"source":["# 1. Load Data"]},{"cell_type":"code","execution_count":2,"id":"8d47eb7d","metadata":{"id":"8d47eb7d","executionInfo":{"status":"ok","timestamp":1692183223424,"user_tz":-540,"elapsed":3277,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from keras_self_attention import SeqSelfAttention\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.utils.vis_utils import plot_model\n","\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","import pickle\n","import random"]},{"cell_type":"code","execution_count":3,"id":"b36dd7cb","metadata":{"id":"b36dd7cb","executionInfo":{"status":"ok","timestamp":1692183223425,"user_tz":-540,"elapsed":12,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["# from tensorflow.python.client import device_lib\n","# tf.config.list_physical_devices('GPU')"]},{"cell_type":"code","execution_count":4,"id":"4ad0110e","metadata":{"id":"4ad0110e","executionInfo":{"status":"ok","timestamp":1692183223425,"user_tz":-540,"elapsed":9,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["\n","seed_num = 42\n","tf.random.set_seed(seed_num)\n","np.random.seed(seed_num)\n","random.seed(seed_num)"]},{"cell_type":"code","execution_count":5,"id":"0UkL8JXHJzzr","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34430,"status":"ok","timestamp":1692183257846,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"},"user_tz":-540},"id":"0UkL8JXHJzzr","outputId":"e6cc90fb-6a4e-4acd-b59d-7729b2662242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"id":"_9lP77I5G0W9","metadata":{"id":"_9lP77I5G0W9","executionInfo":{"status":"ok","timestamp":1692183266133,"user_tz":-540,"elapsed":8295,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["# data load\n","with open('/content/drive/MyDrive/00.multi_emtions/03.models/movies_train.pkl', 'rb') as f:\n","    train_set = pickle.load(f)\n","with open('/content/drive/MyDrive/00.multi_emtions/03.models/movies_test.pkl', 'rb') as f:\n","    test_set = pickle.load(f)\n","with open('/content/drive/MyDrive/00.multi_emtions/03.models/movies_validation.pkl', 'rb') as f:\n","    valid_set = pickle.load(f)\n","\n","\n","# with open(f'{DATA_DIR}/Amazon_Grocery/amazon_grocery_attri.pickle', 'rb') as f:\n","#     attribute = pickle.load(f)\n","\n","# txt\n","# \\"]},{"cell_type":"code","execution_count":7,"id":"2GbWKZyAswxO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1692183266133,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"},"user_tz":-540},"id":"2GbWKZyAswxO","outputId":"84c84eab-be1a-4db7-e852-53d737d43147"},"outputs":[{"output_type":"stream","name":"stdout","text":["train:validation:test = 0.7000:0.1000:0.2000\n"]}],"source":["overall = train_set.shape[0] + valid_set.shape[0] + test_set.shape[0]\n","print('train:validation:test = %.4f:%.4f:%.4f'%((train_set.shape[0] / overall), (valid_set.shape[0] / overall), (test_set.shape[0] / overall)))"]},{"cell_type":"code","execution_count":8,"id":"jXEWWFG23KOv","metadata":{"id":"jXEWWFG23KOv","colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"status":"ok","timestamp":1692183266134,"user_tz":-540,"elapsed":44,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}},"outputId":"2d8b3ec4-f797-4be2-982f-f4d9aa47ed85"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         userID  movieID  rating  compound  senti_score  NeMFRating  \\\n","1633870  143756    31800    1.00    0.5719            3           3   \n","3115182  272600    13746    1.00    0.0000            2           3   \n","2383131  208589    23849    0.50   -0.2023            1           2   \n","2079042  182422    14736    0.75    0.9666            3           3   \n","651398    56973    53386    1.00    0.9260            3           3   \n","...         ...      ...     ...       ...          ...         ...   \n","158490    13844    27705    1.00    0.7351            3           3   \n","1734117  152410    28106    0.75    0.8750            3           3   \n","1564450  137584    43164    1.00    0.6249            3           3   \n","212205    18521    42215    1.00    0.4588            3           3   \n","2759045  241399    52219    0.00    0.9622            3           1   \n","\n","         SBMFRating  anger  anticipation  disgust   fear    joy  sadness  \\\n","1633870           4   0.00          0.00     0.00   0.00  16.67     0.00   \n","3115182           3   0.00         11.11     0.00  11.11   0.00     0.00   \n","2383131           3  10.53          5.26     5.26   5.26   0.00     5.26   \n","2079042           5   5.04          4.20     9.24   8.40   6.72     7.56   \n","651398            5   0.00         27.27     0.00   4.55  18.18     0.00   \n","...             ...    ...           ...      ...    ...    ...      ...   \n","158490            4   0.00          0.00     0.00   0.00   8.00     0.00   \n","1734117           5   0.00          3.77     0.00   3.77   3.77     0.00   \n","1564450           4   0.00          0.00     0.00   0.00   0.00     0.00   \n","212205            4   0.00          0.00     0.00   0.00   0.00     0.00   \n","2759045           5   1.32          4.61     1.97   5.26   6.58     3.29   \n","\n","         surprise  trust  negative  positive  \n","1633870      0.00  33.33      0.00     16.67  \n","3115182      0.00  11.11      0.00      0.00  \n","2383131      5.26   5.26     10.53     10.53  \n","2079042      5.04   4.20     14.29     13.45  \n","651398      13.64  40.91      0.00     27.27  \n","...           ...    ...       ...       ...  \n","158490       0.00  20.00      0.00     12.00  \n","1734117      3.77  11.32      3.77      5.66  \n","1564450      0.00   0.00      0.00     33.33  \n","212205       0.00   0.00      0.00      0.00  \n","2759045      1.32   7.89      9.21     11.18  \n","\n","[2250979 rows x 17 columns]"],"text/html":["\n","\n","  <div id=\"df-3f2300ea-68f0-4a2f-81a4-45ba33f91290\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>movieID</th>\n","      <th>rating</th>\n","      <th>compound</th>\n","      <th>senti_score</th>\n","      <th>NeMFRating</th>\n","      <th>SBMFRating</th>\n","      <th>anger</th>\n","      <th>anticipation</th>\n","      <th>disgust</th>\n","      <th>fear</th>\n","      <th>joy</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>trust</th>\n","      <th>negative</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1633870</th>\n","      <td>143756</td>\n","      <td>31800</td>\n","      <td>1.00</td>\n","      <td>0.5719</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>16.67</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>33.33</td>\n","      <td>0.00</td>\n","      <td>16.67</td>\n","    </tr>\n","    <tr>\n","      <th>3115182</th>\n","      <td>272600</td>\n","      <td>13746</td>\n","      <td>1.00</td>\n","      <td>0.0000</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.00</td>\n","      <td>11.11</td>\n","      <td>0.00</td>\n","      <td>11.11</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>11.11</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2383131</th>\n","      <td>208589</td>\n","      <td>23849</td>\n","      <td>0.50</td>\n","      <td>-0.2023</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>10.53</td>\n","      <td>5.26</td>\n","      <td>5.26</td>\n","      <td>5.26</td>\n","      <td>0.00</td>\n","      <td>5.26</td>\n","      <td>5.26</td>\n","      <td>5.26</td>\n","      <td>10.53</td>\n","      <td>10.53</td>\n","    </tr>\n","    <tr>\n","      <th>2079042</th>\n","      <td>182422</td>\n","      <td>14736</td>\n","      <td>0.75</td>\n","      <td>0.9666</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>5.04</td>\n","      <td>4.20</td>\n","      <td>9.24</td>\n","      <td>8.40</td>\n","      <td>6.72</td>\n","      <td>7.56</td>\n","      <td>5.04</td>\n","      <td>4.20</td>\n","      <td>14.29</td>\n","      <td>13.45</td>\n","    </tr>\n","    <tr>\n","      <th>651398</th>\n","      <td>56973</td>\n","      <td>53386</td>\n","      <td>1.00</td>\n","      <td>0.9260</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0.00</td>\n","      <td>27.27</td>\n","      <td>0.00</td>\n","      <td>4.55</td>\n","      <td>18.18</td>\n","      <td>0.00</td>\n","      <td>13.64</td>\n","      <td>40.91</td>\n","      <td>0.00</td>\n","      <td>27.27</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>158490</th>\n","      <td>13844</td>\n","      <td>27705</td>\n","      <td>1.00</td>\n","      <td>0.7351</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>8.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>20.00</td>\n","      <td>0.00</td>\n","      <td>12.00</td>\n","    </tr>\n","    <tr>\n","      <th>1734117</th>\n","      <td>152410</td>\n","      <td>28106</td>\n","      <td>0.75</td>\n","      <td>0.8750</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0.00</td>\n","      <td>3.77</td>\n","      <td>0.00</td>\n","      <td>3.77</td>\n","      <td>3.77</td>\n","      <td>0.00</td>\n","      <td>3.77</td>\n","      <td>11.32</td>\n","      <td>3.77</td>\n","      <td>5.66</td>\n","    </tr>\n","    <tr>\n","      <th>1564450</th>\n","      <td>137584</td>\n","      <td>43164</td>\n","      <td>1.00</td>\n","      <td>0.6249</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>33.33</td>\n","    </tr>\n","    <tr>\n","      <th>212205</th>\n","      <td>18521</td>\n","      <td>42215</td>\n","      <td>1.00</td>\n","      <td>0.4588</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2759045</th>\n","      <td>241399</td>\n","      <td>52219</td>\n","      <td>0.00</td>\n","      <td>0.9622</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1.32</td>\n","      <td>4.61</td>\n","      <td>1.97</td>\n","      <td>5.26</td>\n","      <td>6.58</td>\n","      <td>3.29</td>\n","      <td>1.32</td>\n","      <td>7.89</td>\n","      <td>9.21</td>\n","      <td>11.18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2250979 rows × 17 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f2300ea-68f0-4a2f-81a4-45ba33f91290')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-495c408b-7c4f-427a-b194-f5ed6249c716\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-495c408b-7c4f-427a-b194-f5ed6249c716')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-495c408b-7c4f-427a-b194-f5ed6249c716 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f2300ea-68f0-4a2f-81a4-45ba33f91290 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f2300ea-68f0-4a2f-81a4-45ba33f91290');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}],"source":["def norm(x):\n","    _max = x.max()\n","    _min = x.min()\n","    _denom = _max - _min\n","    return (x - _min) / _denom\n","\n","train_set['rating'] = norm(train_set['rating'])\n","valid_set['rating'] = norm(valid_set['rating'])\n","train_set"]},{"cell_type":"code","source":["test_set.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akxoQgJ6XWJw","executionInfo":{"status":"ok","timestamp":1692183266134,"user_tz":-540,"elapsed":21,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}},"outputId":"dfdd784b-52aa-4a4c-dca8-fe88b18df3ee"},"id":"akxoQgJ6XWJw","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["userID             0\n","movieID            0\n","rating             0\n","compound           0\n","senti_score        0\n","NeMFRating         0\n","SBMFRating         0\n","anger           5786\n","anticipation    5786\n","disgust         5786\n","fear            5786\n","joy             5786\n","sadness         5786\n","surprise        5786\n","trust           5786\n","negative        5786\n","positive        5786\n","dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","id":"da535f7b","metadata":{"id":"da535f7b"},"source":["# 3.Model"]},{"cell_type":"code","execution_count":10,"id":"0eb9225f","metadata":{"id":"0eb9225f","executionInfo":{"status":"ok","timestamp":1692183266135,"user_tz":-540,"elapsed":18,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["def conv_block(n_layers, latent_dims, names):\n","    ModuleList = []\n","    for i, _ in enumerate(range(n_layers)):\n","        ModuleList.append(Dense(latent_dims, activation='relu', name=f'{names}{i+1}'))\n","        latent_dims //= 2\n","    return ModuleList"]},{"cell_type":"code","execution_count":11,"id":"b0c52eb5","metadata":{"id":"b0c52eb5","executionInfo":{"status":"ok","timestamp":1692183266135,"user_tz":-540,"elapsed":18,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["def ModelBuild(user_num, item_num, id_dims, total_layer_dims, total_n_layer):\n","    seed_num = 42\n","    tf.random.set_seed(seed_num)\n","    np.random.seed(seed_num)\n","    random.seed(seed_num)\n","    # user\n","    user_input = Input(shape=(1,), dtype='int32', name='UserInput')\n","    user_embedding = Embedding(user_num, id_dims, input_length=user_input.shape[1], name='UserIDEmb')(user_input)\n","    user_embedding = Flatten(name='UserFlatten')(user_embedding)\n","\n","    # item\n","    item_input = Input(shape=(1,), dtype='int32', name='ItemInput')\n","    item_embedding = Embedding(item_num, id_dims, input_length=item_input.shape[1], name='ItemIDEmb')(item_input)\n","    item_embedding = Flatten(name='ItemFlatten')(item_embedding)\n","\n","\n","    # GMF\n","    # GMF = Multiply()([user_embedding, item_embedding])\n","\n","    # MLP\n","    MLP_U_I = Concatenate(name='UserItemLayer')([user_embedding, item_embedding])\n","\n","    for layer in conv_block(total_n_layer, total_layer_dims, 'UserItemMLP'):\n","        MLP_U_I = layer(MLP_U_I)\n","\n","        #layer = 2\n","\n","    # Sentiment\n","    # anger_input = Input(shape=(1,), dtype='int32', name='AngerInput')\n","    # anticipation_input = Input(shape=(1,), dtype='int32', name='AnticipationInput')\n","    # disgust_input = Input(shape=(1,), dtype='int32', name='DisgustInput')\n","    # fear_input = Input(shape=(1,), dtype='int32', name='FearInput')\n","    # joy_input = Input(shape=(1,), dtype='int32', name='JoyInput')\n","    # sadness_input = Input(shape=(1,), dtype='int32', name='SadnessInput')\n","    # surprise_input = Input(shape=(1,), dtype='int32', name='SurpriseInput')\n","    # trust_input = Input(shape=(1,), dtype='int32', name='TrustInput')\n","\n","    # Sentiment concatenation\n","    # Sentiment = Concatenate(name='SentimentLayer')([anger_input, anticipation_input, disgust_input, fear_input, joy_input, sadness_input, surprise_input, trust_input])\n","    # Sentiment = Dense(units=8, activation='relu', name='Dense_Sentiment')(Sentiment)\n","\n","    # Final concatenation\n","    # MLP_U_I_S = Concatenate(name='FinalLayer')([MLP_U_I])\n","\n","    # for layer in conv_block(total_n_layer, (total_layer_dims//(2**(total_n_layer-1)))//2, 'MLP'):\n","\n","    #     MLP_U_I_S = layer(MLP_U_I_S)\n","\n","    outputs = Dense(1, activation='sigmoid', name='outputs')(MLP_U_I)\n","    model = Model(inputs=[user_input, item_input], outputs=outputs)\n","    return model"]},{"cell_type":"code","execution_count":12,"id":"Ffsa20fOgW02","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"executionInfo":{"elapsed":556,"status":"error","timestamp":1692183266674,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"},"user_tz":-540},"id":"Ffsa20fOgW02","outputId":"a59c433b-2362-4250-e313-ea8ad840f935"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-662cf084f705>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["plot_model(model, show_shapes=True, show_layer_names=True)"]},{"cell_type":"markdown","source":["# 파라미터 튜닝\n","- id_dim = [256, 128, 64]\n","- n layer = [2,3]\n","- layer_dim = [128, 64, 32]\n","- lr = [0.005, 0.001]"],"metadata":{"id":"Qz-BM99AnoPF"},"id":"Qz-BM99AnoPF"},{"cell_type":"code","execution_count":13,"id":"fdfa0d09","metadata":{"id":"fdfa0d09","executionInfo":{"status":"ok","timestamp":1692183282384,"user_tz":-540,"elapsed":552,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["def model_run_param(id_dims, total_layer_dims,total_n_layer, lr):\n","    seed_num = 42\n","    tf.random.set_seed(seed_num)\n","    np.random.seed(seed_num)\n","    random.seed(seed_num)\n","\n","    model = ModelBuild(user_num = user_num, item_num = item_num, id_dims = id_dims, total_layer_dims = total_layer_dims, total_n_layer = total_n_layer)\n","\n","    adam = Adam(learning_rate=lr)\n","    model.compile(optimizer=adam, loss='binary_crossentropy')\n","    es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, patience = 3, restore_best_weights = True)\n","    # model.summary()\n","\n","    history = model.fit([train_set['userID'], train_set['movieID']],\n","                train_set['rating'],\n","                batch_size = 1024,\n","                epochs = 100,\n","                callbacks=[es],\n","                validation_data = ([valid_set['userID'], valid_set['movieID']],\n","                valid_set['rating']))\n","\n","    prediction = model.predict([test_set['userID'], test_set['movieID']])\n","    prediction = 4 * norm(prediction) + 1\n","    # prediction = 4 * prediction + 1\n","\n","    MAE_temp = mean_absolute_error(test_set['rating'], prediction)\n","    RMSE_temp = mean_squared_error(test_set['rating'], prediction, squared = False)\n","    embedding_size = id_dims\n","    layer_dim = total_layer_dims\n","    lr = lr\n","    n_layer = total_n_layer\n","    print(f'embedding:{embedding_size}, layer_dim:{layer_dim},n_layer:{n_layer},lr:{lr}')\n","    print(f'MAE: {MAE_temp:.3f}')\n","    print(f'RMSE: {RMSE_temp:.3f}')\n","\n","    return MAE_temp, RMSE_temp, embedding_size, layer_dim, n_layer, lr"]},{"cell_type":"code","execution_count":14,"id":"9b004e06","metadata":{"id":"9b004e06","executionInfo":{"status":"ok","timestamp":1692183287108,"user_tz":-540,"elapsed":443,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"outputs":[],"source":["user_num = 281335\n","item_num = 59044\n","\n","id_dims = [256, 128, 64, 32]\n","total_layer_dims = [128, 64,32]\n","total_n_layer = [3]\n","lr = [0.005, 0.001]"]},{"cell_type":"code","source":["MAE, RMSE, param_embedding, param_layer_dim, param_n_layer, param_lr = [], [], [], [], [], []\n","for a in id_dims:\n","  for b in total_layer_dims:\n","    for i in lr:\n","      for j in total_n_layer:\n","        MAE_temp, RMSE_temp, embedding_size, layer_dim, n_layer, learning_rate = model_run_param(a, b,j,i)\n","\n","        MAE.append(MAE_temp)\n","        RMSE.append(RMSE_temp)\n","        param_embedding.append(embedding_size)\n","        param_layer_dim.append(layer_dim)\n","        param_n_layer.append(n_layer)\n","        param_lr.append(learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THnxgiy0oMwF","executionInfo":{"status":"ok","timestamp":1692186143217,"user_tz":-540,"elapsed":2854837,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}},"outputId":"eea9c3fc-e7f8-480e-9190-05dc87450ac5"},"id":"THnxgiy0oMwF","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","2199/2199 [==============================] - 45s 17ms/step - loss: 0.4296 - val_loss: 0.4124\n","Epoch 2/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3793 - val_loss: 0.4127\n","Epoch 3/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3454 - val_loss: 0.4297\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3054Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3054 - val_loss: 0.4768\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:256, layer_dim:128,n_layer:3,lr:0.005\n","MAE: 0.704\n","RMSE: 0.971\n","Epoch 1/100\n","2199/2199 [==============================] - 35s 15ms/step - loss: 0.4296 - val_loss: 0.4105\n","Epoch 2/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3765 - val_loss: 0.4129\n","Epoch 3/100\n","2199/2199 [==============================] - 21s 9ms/step - loss: 0.3276 - val_loss: 0.4403\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.2766Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.2766 - val_loss: 0.4828\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:256, layer_dim:128,n_layer:3,lr:0.001\n","MAE: 0.690\n","RMSE: 0.967\n","Epoch 1/100\n","2199/2199 [==============================] - 36s 15ms/step - loss: 0.4297 - val_loss: 0.4118\n","Epoch 2/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3793 - val_loss: 0.4132\n","Epoch 3/100\n","2199/2199 [==============================] - 21s 9ms/step - loss: 0.3480 - val_loss: 0.4329\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3124Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3124 - val_loss: 0.4710\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:256, layer_dim:64,n_layer:3,lr:0.005\n","MAE: 0.704\n","RMSE: 0.971\n","Epoch 1/100\n","2199/2199 [==============================] - 36s 15ms/step - loss: 0.4307 - val_loss: 0.4106\n","Epoch 2/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3777 - val_loss: 0.4117\n","Epoch 3/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3391 - val_loss: 0.4303\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.2959Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 22s 10ms/step - loss: 0.2959 - val_loss: 0.4741\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:256, layer_dim:64,n_layer:3,lr:0.001\n","MAE: 0.695\n","RMSE: 0.967\n","Epoch 1/100\n","2199/2199 [==============================] - 36s 15ms/step - loss: 0.4296 - val_loss: 0.4115\n","Epoch 2/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3797 - val_loss: 0.4129\n","Epoch 3/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3531 - val_loss: 0.4278\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3251Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3251 - val_loss: 0.4557\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:256, layer_dim:32,n_layer:3,lr:0.005\n","MAE: 0.696\n","RMSE: 0.970\n","Epoch 1/100\n","2199/2199 [==============================] - 35s 15ms/step - loss: 0.4319 - val_loss: 0.4107\n","Epoch 2/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3799 - val_loss: 0.4107\n","Epoch 3/100\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3512 - val_loss: 0.4252\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3196Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 21s 10ms/step - loss: 0.3196 - val_loss: 0.4505\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:256, layer_dim:32,n_layer:3,lr:0.001\n","MAE: 0.688\n","RMSE: 0.967\n","Epoch 1/100\n","2199/2199 [==============================] - 34s 15ms/step - loss: 0.4295 - val_loss: 0.4113\n","Epoch 2/100\n","2199/2199 [==============================] - 16s 7ms/step - loss: 0.3792 - val_loss: 0.4120\n","Epoch 3/100\n","2199/2199 [==============================] - 16s 7ms/step - loss: 0.3442 - val_loss: 0.4304\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3019Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3019 - val_loss: 0.4787\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:128, layer_dim:128,n_layer:3,lr:0.005\n","MAE: 0.697\n","RMSE: 0.970\n","Epoch 1/100\n","2199/2199 [==============================] - 29s 12ms/step - loss: 0.4299 - val_loss: 0.4106\n","Epoch 2/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3771 - val_loss: 0.4128\n","Epoch 3/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3288 - val_loss: 0.4378\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.2775Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.2775 - val_loss: 0.4827\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:128, layer_dim:128,n_layer:3,lr:0.001\n","MAE: 0.694\n","RMSE: 0.968\n","Epoch 1/100\n","2199/2199 [==============================] - 29s 12ms/step - loss: 0.4294 - val_loss: 0.4113\n","Epoch 2/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3789 - val_loss: 0.4134\n","Epoch 3/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3469 - val_loss: 0.4309\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3099Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3099 - val_loss: 0.4787\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:128, layer_dim:64,n_layer:3,lr:0.005\n","MAE: 0.691\n","RMSE: 0.969\n","Epoch 1/100\n","2199/2199 [==============================] - 30s 13ms/step - loss: 0.4309 - val_loss: 0.4104\n","Epoch 2/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3786 - val_loss: 0.4116\n","Epoch 3/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3423 - val_loss: 0.4297\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.2985Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.2985 - val_loss: 0.4715\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:128, layer_dim:64,n_layer:3,lr:0.001\n","MAE: 0.692\n","RMSE: 0.967\n","Epoch 1/100\n","2199/2199 [==============================] - 29s 12ms/step - loss: 0.4294 - val_loss: 0.4113\n","Epoch 2/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3790 - val_loss: 0.4130\n","Epoch 3/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3499 - val_loss: 0.4290\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3201Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3201 - val_loss: 0.4617\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:128, layer_dim:32,n_layer:3,lr:0.005\n","MAE: 0.693\n","RMSE: 0.970\n","Epoch 1/100\n","2199/2199 [==============================] - 29s 12ms/step - loss: 0.4324 - val_loss: 0.4108\n","Epoch 2/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3809 - val_loss: 0.4106\n","Epoch 3/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3535 - val_loss: 0.4241\n","Epoch 4/100\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.3228 - val_loss: 0.4455\n","Epoch 5/100\n","2192/2199 [============================>.] - ETA: 0s - loss: 0.2942Restoring model weights from the end of the best epoch: 2.\n","2199/2199 [==============================] - 15s 7ms/step - loss: 0.2942 - val_loss: 0.4743\n","Epoch 5: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:128, layer_dim:32,n_layer:3,lr:0.001\n","MAE: 0.662\n","RMSE: 0.964\n","Epoch 1/100\n","2199/2199 [==============================] - 32s 14ms/step - loss: 0.4293 - val_loss: 0.4111\n","Epoch 2/100\n","2199/2199 [==============================] - 13s 6ms/step - loss: 0.3791 - val_loss: 0.4127\n","Epoch 3/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3439 - val_loss: 0.4333\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3021Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3021 - val_loss: 0.4756\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:64, layer_dim:128,n_layer:3,lr:0.005\n","MAE: 0.701\n","RMSE: 0.970\n","Epoch 1/100\n","2199/2199 [==============================] - 27s 12ms/step - loss: 0.4303 - val_loss: 0.4106\n","Epoch 2/100\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.3790 - val_loss: 0.4119\n","Epoch 3/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3378 - val_loss: 0.4343\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.2875Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.2875 - val_loss: 0.4814\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:64, layer_dim:128,n_layer:3,lr:0.001\n","MAE: 0.695\n","RMSE: 0.968\n","Epoch 1/100\n","2199/2199 [==============================] - 27s 12ms/step - loss: 0.4292 - val_loss: 0.4110\n","Epoch 2/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3785 - val_loss: 0.4132\n","Epoch 3/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3457 - val_loss: 0.4357\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3063Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.3063 - val_loss: 0.4758\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:64, layer_dim:64,n_layer:3,lr:0.005\n","MAE: 0.693\n","RMSE: 0.968\n","Epoch 1/100\n","2199/2199 [==============================] - 27s 11ms/step - loss: 0.4314 - val_loss: 0.4107\n","Epoch 2/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3801 - val_loss: 0.4111\n","Epoch 3/100\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.3482 - val_loss: 0.4264\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3079Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3079 - val_loss: 0.4701\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:64, layer_dim:64,n_layer:3,lr:0.001\n","MAE: 0.696\n","RMSE: 0.969\n","Epoch 1/100\n","2199/2199 [==============================] - 27s 11ms/step - loss: 0.4292 - val_loss: 0.4109\n","Epoch 2/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3783 - val_loss: 0.4130\n","Epoch 3/100\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.3512 - val_loss: 0.4306\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3251Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3251 - val_loss: 0.4537\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:64, layer_dim:32,n_layer:3,lr:0.005\n","MAE: 0.689\n","RMSE: 0.968\n","Epoch 1/100\n","2199/2199 [==============================] - 27s 11ms/step - loss: 0.4329 - val_loss: 0.4111\n","Epoch 2/100\n","2199/2199 [==============================] - 12s 6ms/step - loss: 0.3821 - val_loss: 0.4104\n","Epoch 3/100\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.3578 - val_loss: 0.4223\n","Epoch 4/100\n","2199/2199 [==============================] - 12s 5ms/step - loss: 0.3309 - val_loss: 0.4454\n","Epoch 5/100\n","2198/2199 [============================>.] - ETA: 0s - loss: 0.3019Restoring model weights from the end of the best epoch: 2.\n","2199/2199 [==============================] - 11s 5ms/step - loss: 0.3019 - val_loss: 0.4746\n","Epoch 5: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:64, layer_dim:32,n_layer:3,lr:0.001\n","MAE: 0.666\n","RMSE: 0.964\n","Epoch 1/100\n","2199/2199 [==============================] - 30s 13ms/step - loss: 0.4294 - val_loss: 0.4112\n","Epoch 2/100\n","2199/2199 [==============================] - 11s 5ms/step - loss: 0.3802 - val_loss: 0.4120\n","Epoch 3/100\n","2199/2199 [==============================] - 11s 5ms/step - loss: 0.3486 - val_loss: 0.4317\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3098Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 11s 5ms/step - loss: 0.3098 - val_loss: 0.4672\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:32, layer_dim:128,n_layer:3,lr:0.005\n","MAE: 0.698\n","RMSE: 0.969\n","Epoch 1/100\n","2199/2199 [==============================] - 25s 10ms/step - loss: 0.4311 - val_loss: 0.4110\n","Epoch 2/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3807 - val_loss: 0.4121\n","Epoch 3/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3479 - val_loss: 0.4280\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3052Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3052 - val_loss: 0.4723\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 28s 1ms/step\n","embedding:32, layer_dim:128,n_layer:3,lr:0.001\n","MAE: 0.703\n","RMSE: 0.972\n","Epoch 1/100\n","2199/2199 [==============================] - 25s 10ms/step - loss: 0.4292 - val_loss: 0.4110\n","Epoch 2/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3789 - val_loss: 0.4124\n","Epoch 3/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3504 - val_loss: 0.4294\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3185Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3185 - val_loss: 0.4657\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:32, layer_dim:64,n_layer:3,lr:0.005\n","MAE: 0.692\n","RMSE: 0.968\n","Epoch 1/100\n","2199/2199 [==============================] - 25s 10ms/step - loss: 0.4320 - val_loss: 0.4111\n","Epoch 2/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3822 - val_loss: 0.4109\n","Epoch 3/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3564 - val_loss: 0.4236\n","Epoch 4/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3244 - val_loss: 0.4562\n","Epoch 5/100\n","2190/2199 [============================>.] - ETA: 0s - loss: 0.2920Restoring model weights from the end of the best epoch: 2.\n","2199/2199 [==============================] - 10s 4ms/step - loss: 0.2920 - val_loss: 0.4881\n","Epoch 5: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:32, layer_dim:64,n_layer:3,lr:0.001\n","MAE: 0.666\n","RMSE: 0.964\n","Epoch 1/100\n","2199/2199 [==============================] - 24s 10ms/step - loss: 0.4293 - val_loss: 0.4107\n","Epoch 2/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3791 - val_loss: 0.4121\n","Epoch 3/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3532 - val_loss: 0.4306\n","Epoch 4/100\n","2199/2199 [==============================] - ETA: 0s - loss: 0.3263Restoring model weights from the end of the best epoch: 1.\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3263 - val_loss: 0.4567\n","Epoch 4: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:32, layer_dim:32,n_layer:3,lr:0.005\n","MAE: 0.690\n","RMSE: 0.967\n","Epoch 1/100\n","2199/2199 [==============================] - 25s 10ms/step - loss: 0.4335 - val_loss: 0.4113\n","Epoch 2/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3832 - val_loss: 0.4107\n","Epoch 3/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3606 - val_loss: 0.4219\n","Epoch 4/100\n","2199/2199 [==============================] - 10s 5ms/step - loss: 0.3379 - val_loss: 0.4410\n","Epoch 5/100\n","2191/2199 [============================>.] - ETA: 0s - loss: 0.3126Restoring model weights from the end of the best epoch: 2.\n","2199/2199 [==============================] - 10s 4ms/step - loss: 0.3127 - val_loss: 0.4653\n","Epoch 5: early stopping\n","20099/20099 [==============================] - 29s 1ms/step\n","embedding:32, layer_dim:32,n_layer:3,lr:0.001\n","MAE: 0.667\n","RMSE: 0.964\n"]}]},{"cell_type":"code","source":["mlp_dfnorm = pd.DataFrame(zip(param_embedding, param_layer_dim, param_n_layer, param_lr, MAE, RMSE), columns=['embedding size','layer_dim','N layer', 'Learning Rate','MAE','RMSE'])\n","mlp_dfnorm"],"metadata":{"id":"UC4D6zW3oMyZ","executionInfo":{"status":"ok","timestamp":1692186143218,"user_tz":-540,"elapsed":26,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}},"colab":{"base_uri":"https://localhost:8080/","height":802},"outputId":"152cb7b2-dba8-443f-e7f0-26ba2a009f83"},"id":"UC4D6zW3oMyZ","execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    embedding size  layer_dim  N layer  Learning Rate       MAE      RMSE\n","0              256        128        3          0.005  0.703962  0.971298\n","1              256        128        3          0.001  0.690235  0.966966\n","2              256         64        3          0.005  0.704200  0.970989\n","3              256         64        3          0.001  0.695212  0.967415\n","4              256         32        3          0.005  0.695763  0.970100\n","5              256         32        3          0.001  0.687912  0.966814\n","6              128        128        3          0.005  0.697252  0.970135\n","7              128        128        3          0.001  0.694183  0.967510\n","8              128         64        3          0.005  0.691440  0.969248\n","9              128         64        3          0.001  0.691918  0.966840\n","10             128         32        3          0.005  0.693358  0.969680\n","11             128         32        3          0.001  0.662461  0.964005\n","12              64        128        3          0.005  0.700566  0.970322\n","13              64        128        3          0.001  0.695484  0.968323\n","14              64         64        3          0.005  0.692588  0.967556\n","15              64         64        3          0.001  0.695679  0.968699\n","16              64         32        3          0.005  0.688892  0.968098\n","17              64         32        3          0.001  0.665882  0.963525\n","18              32        128        3          0.005  0.698151  0.968669\n","19              32        128        3          0.001  0.703448  0.971985\n","20              32         64        3          0.005  0.692413  0.968290\n","21              32         64        3          0.001  0.665958  0.964065\n","22              32         32        3          0.005  0.690046  0.967441\n","23              32         32        3          0.001  0.666571  0.963542"],"text/html":["\n","\n","  <div id=\"df-48ae7d75-3198-47d8-8dc3-2f4d8d1111d1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>embedding size</th>\n","      <th>layer_dim</th>\n","      <th>N layer</th>\n","      <th>Learning Rate</th>\n","      <th>MAE</th>\n","      <th>RMSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>256</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.703962</td>\n","      <td>0.971298</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>256</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.690235</td>\n","      <td>0.966966</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>256</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.704200</td>\n","      <td>0.970989</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>256</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.695212</td>\n","      <td>0.967415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>256</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.695763</td>\n","      <td>0.970100</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>256</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.687912</td>\n","      <td>0.966814</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>128</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.697252</td>\n","      <td>0.970135</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>128</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.694183</td>\n","      <td>0.967510</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>128</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.691440</td>\n","      <td>0.969248</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>128</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.691918</td>\n","      <td>0.966840</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>128</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.693358</td>\n","      <td>0.969680</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>128</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.662461</td>\n","      <td>0.964005</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>64</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.700566</td>\n","      <td>0.970322</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>64</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.695484</td>\n","      <td>0.968323</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>64</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.692588</td>\n","      <td>0.967556</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>64</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.695679</td>\n","      <td>0.968699</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>64</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.688892</td>\n","      <td>0.968098</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>64</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.665882</td>\n","      <td>0.963525</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>32</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.698151</td>\n","      <td>0.968669</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>32</td>\n","      <td>128</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.703448</td>\n","      <td>0.971985</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>32</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.692413</td>\n","      <td>0.968290</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>32</td>\n","      <td>64</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.665958</td>\n","      <td>0.964065</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>32</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.005</td>\n","      <td>0.690046</td>\n","      <td>0.967441</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>32</td>\n","      <td>32</td>\n","      <td>3</td>\n","      <td>0.001</td>\n","      <td>0.666571</td>\n","      <td>0.963542</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48ae7d75-3198-47d8-8dc3-2f4d8d1111d1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-01d385d8-7367-4290-a783-35ae020a2625\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01d385d8-7367-4290-a783-35ae020a2625')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-01d385d8-7367-4290-a783-35ae020a2625 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-48ae7d75-3198-47d8-8dc3-2f4d8d1111d1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-48ae7d75-3198-47d8-8dc3-2f4d8d1111d1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# 결과 저장\n","mlp_dfnorm.to_csv(\"/content/drive/MyDrive/00.multi_emtions/02.result/000.Final_MLP_result.csv\",index=False)"],"metadata":{"id":"DnGSx-qpYOHP","executionInfo":{"status":"ok","timestamp":1692186143753,"user_tz":-540,"elapsed":542,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"id":"DnGSx-qpYOHP","execution_count":17,"outputs":[]},{"cell_type":"code","source":["mlp_df2"],"metadata":{"id":"p753qC8tPoN_","executionInfo":{"status":"aborted","timestamp":1692183266678,"user_tz":-540,"elapsed":15,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"id":"p753qC8tPoN_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlp_df"],"metadata":{"id":"kkkavY4LoM0r","executionInfo":{"status":"aborted","timestamp":1692183266679,"user_tz":-540,"elapsed":16,"user":{"displayName":"Ji Hyun Kim","userId":"08933706957203627791"}}},"id":"kkkavY4LoM0r","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuClass":"premium","gpuType":"V100","machine_shape":"hm","provenance":[],"toc_visible":true},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"209px"},"toc_section_display":true,"toc_window_display":false},"vscode":{"interpreter":{"hash":"cfdf8ef8346a21885da917cae83aeb1299c45b2bb56f33706d6a0a3fcfc6b624"}}},"nbformat":4,"nbformat_minor":5}